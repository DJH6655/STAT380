---
title: "STAT380 Project"
author: "Dylan Holliday and Nixon Kameen"
date: "2025-11-30"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Install Packages:

```{r}
library(RKaggle)
library(dplyr)
library(ggplot2)
library(tidyr)
library(caret)
library(class)
library(randomForest)
```


Read in Data

```{r}
loan_approval <- get_dataset("architsharma01/loan-approval-prediction-dataset")

loan_approval %>% head()
```

## Task 1
Research Question: What basic patterns appear in the dataset regarding income, credit score, and loan approval status?


Let's first understand how many loans are approved vs. rejected:
```{r}
loan_approval %>% ggplot(aes(x = loan_status)) +
  geom_bar() +
  theme_minimal()
```
The dataset contains more approved loans than rejected ones, indicating a moderate class imbalance where approvals occur substantially more frequently than rejections

Next, lets take a look at a simple histogram to show how income is spread.
```{r}
loan_approval %>%
  ggplot(aes(x = income_annum)) +
  geom_histogram(fill = "darkorange", color="black", bins = 30) +
  theme_minimal() +
  labs(title = "Distribution of Annual Income",
       x = "Annual Income",
       y = "Count")
```
Annual income is spread fairly evenly across a wide range, with no single income level dominating the dataset, indicating that applicants come from a broad variety of financial backgrounds.

Next, lets take a look at credit scores in relation to loan status
```{r}
loan_approval %>%
  ggplot(aes(x = loan_status, y = cibil_score, fill = loan_status)) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "CIBIL Score by Loan Status",
       x = "Loan Status",
       y = "CIBIL Score")
```
Approved applicants tend to have significantly higher CIBIL scores than rejected applicants, indicating that credit score is a strong differentiator in loan approval decisions

##Task 2
Research Question: Which applicant characteristics are associated with the requested loan amount, and how does annual income relate to loan amount within a linear regression model?

To build our linear regression model for loan amount, we use forward selection. This method starts with an empty model and adds predictors one at a time. At each step, it chooses the variable that improves the model the most based on AIC. The process continues until adding more variables no longer helps. This approach keeps the model easy to interpret while still including the predictors that actually matter.

Null model (no predictors)
```{r}
null_model <- lm(loan_amount ~ 1, data = loan_approval)
```

Full model (all numeric predictors)
```{r}
# Full model (all numeric predictors)
full_model <- lm(loan_amount ~ income_annum +
                                   cibil_score +
                                   loan_term +
                                   no_of_dependents +
                                   residential_assets_value +
                                   commercial_assets_value +
                                   luxury_assets_value +
                                   bank_asset_value,
                                   data = loan_approval)
```

Forward Selection
```{r}
step_model <- step(null_model,
                   scope = formula(full_model),
                   direction = "forward",
                   trace = FALSE)

summary(step_model)
```
Forward selection produced a model with annual income, commercial asset value, and number of dependents as the key predictors of loan amount. Income is the strongest predictor, with higher–income applicants requesting larger loans. Commercial assets also have a small positive effect, while number of dependents has a weaker negative effect. Overall, the model explains a large share of the variation in loan amount (R² ≈ 0.86), indicating that these financial factors play an important role in loan size.

```{r}
loan_approval %>%
  ggplot(aes(x = income_annum, y = loan_amount)) +
  geom_point(alpha = 0.4) +
  geom_smooth(method = "lm", se = FALSE, color="blue") +
  theme_minimal() +
  labs(title = "Loan Amount vs Annual Income",
       x = "Annual Income",
       y = "Loan Amount")
```
There is a strong positive relationship between annual income and loan amount, with higher–income applicants consistently requesting larger loans.


##Task 3
Question:
We want to know if loan information, annual income, credit score, and asset valuation can accurately predict whether the proposed loan will be accepted or rejected. We want to set a standard of 90% for our model's goal accuracy, but we will also look at other performance metrics to get a better understanding of Where the model is excelling and failing. We will use logistic regression as a baseline model and compare its performance with that of kNN and a Random Forest Classifier.

The distribution has many observations in each category meaning that we do not necessarily have to address the imbalance of classes. However, the difference is enough to merit keeping an eye on the F1 score as opposed to accuracy for our model predictions.

First let's convert the loan status variable to be 0 or 1 to make the data better for model usage:

```{r}
loan_approval <- loan_approval %>%
  mutate(
    loan_status = if_else(loan_status == 'Approved', 1, 0)
  )
```


Let's implement a Logistic Regression model and apply ten-fold cross validation to retrieve the performance metrics:

```{r}
#Assign folds values and permute
num_folds <- 10
folds <- cut(x = 1:nrow(loan_approval), breaks = num_folds, labels = FALSE)

set.seed(123)
folds <- sample(folds)
set.seed(NULL)

#Create storage for loop output
met_mat <- matrix(NA, nrow = num_folds, ncol = 2)

#Loop
for (i in 1:num_folds) {
  Test_ind <- which(folds == i)
  Test_set <- loan_approval[Test_ind, ]
  Train_set <- loan_approval[-Test_ind, ]
  
  #Build Model
  log_model <- glm(loan_status ~ no_of_dependents +
                     education + self_employed +
                     income_annum + loan_amount +
                     loan_term + cibil_score +
                     residential_assets_value +
                     commercial_assets_value +
                     luxury_assets_value +
                     bank_asset_value, 
                   data = Train_set)
    

  #Make predictions
  pred_log <- predict(log_model,
                      newdata = Test_set, 
                      type = 'response')
  
  #Apply threshold
  pred_log <- factor(if_else(pred_log > .5, 1, 0))
  act_log <- factor(Test_set$loan_status)
  
  # Calculate Accuracy and F1 score
  accuracy <- mean(pred_log == act_log)
  
  metrics <- confusionMatrix(pred_log, act_log,
                             mode = "everything", positive = "1") 
  
  f1 <- metrics$byClass["F1"]
  
  
  #Add to the Accuracy vector
  met_mat[i, 1] = accuracy
  met_mat[i, 2] = f1
}

#Calculate the mean across folds
avg_acc <- mean(met_mat[ , 1])
avg_f1 <- mean(met_mat[ , 2])

avg_acc
avg_f1
```

The accuracy is above 90 percent while the F1 Score is even higher. This means the model is performing well. Let's test these numbers against other models:

kNN Model:

First, we must standardize our variables.

```{r}
#Change all variables to numeric
loan_knn <- loan_approval %>%
  mutate(
    education = ifelse(education == 'Graduate', 1, 0),
    self_employed = ifelse(self_employed == 'Yes', 1, 0)
  )


#Scale by numeric variables
xvars <- c('no_of_dependents',
                     'education', 'self_employed',
                     'income_annum', 'loan_amount',
                     'loan_term', 'cibil_score',
                     'residential_assets_value',
                     'commercial_assets_value',
                     'luxury_assets_value',
                     'bank_asset_value')
loan_knn[, xvars] <- scale(loan_knn[ ,xvars], center = TRUE, scale = TRUE)
```

To choose the value k for the KNN model, I will perform a 5 fold cross-validation and plot the accuracy against the mean values of k across the 5 folds. This is a good way to pick k because it lessens the error due to random split, and accuracy is a good general test metric to choose a classification model off of.

```{r}
#Assign folds values and permute
num_folds <- 5
folds <- cut(x = 1:nrow(loan_knn), breaks = num_folds, labels = FALSE)

set.seed(1103)
folds <- sample(folds)
set.seed(NULL)

#Assign constants and create storage for loop output
maxK <- 40
ACC_mat <- matrix(NA, nrow = num_folds, ncol = maxK)

#Loop
for (i in 1:num_folds) {
  Test_ind <- which(folds == i)
  Test <- loan_knn[Test_ind, ]
  Train <- loan_knn[-Test_ind, ]
  
  for (j in 2:maxK) {
    #Build Model
    knn_res <- knn(train = Train[ , xvars, drop = FALSE],
                       test = Test[ , xvars, drop = FALSE],
                       cl = Train$loan_status,
                       k = j)
    
    #Add Predictions to test set
    Test <- Test %>%
      mutate(pred_status = knn_res)
    
    # Calculate Accuracy
    accuracy <- mean(Test$pred_status == Test$loan_status)
    
    #Add to the Accuracy matrix
    ACC_mat[i,j] <- accuracy
  }
}

#Calculate the mean across folds
ACC_vec <- colMeans(ACC_mat)

ACC_df <- data.frame(NN= 1:40, ACC = ACC_vec)

#Plot the accuracy against k for each model
ggplot(data = ACC_df, mapping = aes(x = NN, y = ACC)) +
  geom_line() +
  labs(x = "Number of Nearest Neighbors",
       y = "Accuracy") +
  theme_minimal()

```
From this plot, k = 15 looks like a good k because the accuracy does not increase by much after that.

Let's try 10 fold cross validation for this value of k and a different seed and compile the results.


```{r}
#Assign folds values and permute
num_folds <- 10
folds <- cut(x = 1:nrow(loan_knn), breaks = num_folds, labels = FALSE)

set.seed(123)
folds <- sample(folds)
set.seed(NULL)

#Assign constants and create storage for loop output
met_mat <- matrix(NA, nrow = num_folds, ncol = 2)

#Loop
for (i in 1:num_folds) {
  Test_ind <- which(folds == i)
  Test <- loan_knn[Test_ind, ]
  Train <- loan_knn[-Test_ind, ]
  
  
  #Build Model
  knn_res <- knn(train = Train[ , xvars, drop = FALSE],
                      test = Test[ , xvars, drop = FALSE],
                      cl = Train$loan_status,
                      k = 15)
    
  #Add Predictions to test set
  Test <- Test %>%
    mutate(pred_status = knn_res)
    
  #Separate predictions and results
  pred_knn <- factor(Test$pred_status)
  act_knn <- factor(Test$loan_status)
  
  # Calculate Accuracy and F1 score
  accuracy <- mean(pred_knn == act_knn)
  
  metrics <- confusionMatrix(pred_knn,
                             act_knn,
                             mode = "everything", positive = "1") 
  
  f1 <- metrics$byClass["F1"]
  
  
  #Add to the Accuracy vector
  met_mat[i, 1] = accuracy
  met_mat[i, 2] = f1
}

#Calculate the mean across folds
avg_acc <- mean(met_mat[ , 1])
avg_f1 <- mean(met_mat[ , 2])

avg_acc
avg_f1
```

These results show that the knn model performs about as well as the logistic regression model, with only a slightly worse accuracy and f1 score than the logistic regression model.
















